{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#All necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "#A progress bar indicator\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121\n",
    "import keras\n",
    "import cv2\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random seed, so that code can be run against same input\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "#fixed constants\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "TEST_SIZE = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis\n",
       "0  000c1434d8d7          2\n",
       "1  001639a390f0          4\n",
       "2  0024cdab0c1e          1\n",
       "3  002c21358ce6          0\n",
       "4  005b95c28852          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1805\n",
       "2     999\n",
       "1     370\n",
       "4     295\n",
       "3     193\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_width(image, new_shape, is_rgb=True):\n",
    "    #Pad image to get same sizing\n",
    "    pad_diff = new_shape - image.shape[0], new_shape - image.shape[1]\n",
    "    t, b = math.floor(pad_diff[0]/2), math.ceil(pad_diff[0]/2)\n",
    "    l, r = math.floor(pad_diff[1]/2), math.ceil(pad_diff[1]/2)\n",
    "    if is_rgb:\n",
    "        pad_width = ((t,b), (l,r), (0, 0))\n",
    "    else:\n",
    "        pad_width = ((t,b), (l,r))\n",
    "    return pad_width\n",
    "\n",
    "def crop_image_from_gray(image, tol=7):\n",
    "    #Crop images to obtain section of only eye\n",
    "    if image.ndim == 2:\n",
    "        mask = image > tol\n",
    "        return image[np.ix_(mask.any(1), mask.any(0))]\n",
    "    elif image.ndim == 3:\n",
    "        gray_img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img > tol\n",
    "      \n",
    "        check_shape = image[:, :, 0][np.ix_(mask.any(1), mask.any(0))].shape[0]\n",
    "        #If the image was too dark, don't do anything to the original one\n",
    "        if (check_shape == 0):\n",
    "            return image \n",
    "        else:\n",
    "            img1=image[:, :, 0][np.ix_(mask.any(1), mask.any(0))]\n",
    "            img2=image[:, :, 1][np.ix_(mask.any(1), mask.any(0))]\n",
    "            img3=image[:, :, 2][np.ix_(mask.any(1), mask.any(0))]\n",
    "            image = np.stack([img1, img2, img3], axis=-1)\n",
    "        return image\n",
    "\n",
    "def load_ben_color(image, sigmaX):\n",
    "    #convert image color to rgb\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0), sigmaX),-4, 128)\n",
    "    return image\n",
    "\n",
    "def preprocess_image(image_path, desired_size = 224):\n",
    "    #Resize the image and add perform all required preprocessing\n",
    "    image = cv2.imread(image_path)\n",
    "    image = load_ben_color(image, sigmaX = 30)\n",
    "    image = cv2.resize(image, (desired_size, desired_size))\n",
    "    image[:, :, 0] = image[:, :, 1]\n",
    "    image[:, :, 2] = image[:, :, 1]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3662/3662 [57:19<00:00,  1.06it/s]  \n"
     ]
    }
   ],
   "source": [
    "#Do all necessary preprocessing and place in array\n",
    "N = train_df.shape[0]\n",
    "x_train = np.empty((N, 224, 224, 3), dtype=np.uint8)\n",
    "\n",
    "for i, image_id in enumerate(tqdm(train_df['id_code'])):\n",
    "    x_train[i, :, :, :] = preprocess_image(f'dataset/images/{image_id}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode\n",
    "y_train = pd.get_dummies(train_df['diagnosis']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original y_train: [1805  370  999  193  295]\n",
      "Multilabel y_train: [3662 1857 1487  488  295]\n"
     ]
    }
   ],
   "source": [
    "#The following generates multi label classification\n",
    "#This is done because if for instance an image is of level 4\n",
    "#It is related to all the other levels before it\n",
    "#IOW the levels aren't mutually exclusive\n",
    "#Ex: - generally lv 4 -> [0, 0, 0, 1]; in this case [1, 1, 1, 1]\n",
    "y_train_multi = np.empty(y_train.shape, dtype=y_train.dtype)\n",
    "y_train_multi[:, 4] = y_train[:, 4]\n",
    "\n",
    "for i in range(3, -1, -1):\n",
    "    y_train_multi[:, i] = np.logical_or(y_train[:, i], y_train_multi[:, i+1])\n",
    "\n",
    "print(\"Original y_train:\", y_train.sum(axis=0))\n",
    "print(\"Multilabel y_train:\", y_train_multi.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train_multi, test_size=TEST_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image data generator for data Augmentation\n",
    "def create_datagen():\n",
    "    return ImageDataGenerator(\n",
    "        zoom_range=0.15,  \n",
    "        fill_mode='constant',\n",
    "        cval=0.,  \n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "    )\n",
    "\n",
    "# Using original generator\n",
    "data_generator = create_datagen().flow(x_train, y_train, batch_size=BATCH_SIZE, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the DensetNet121 model, loading a pretrained weight to prevent unnecessary training\n",
    "base_model = DenseNet121(include_top=False, weights=\"../pretrained_weights/densenet_weights/notop.h5\", input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "\n",
    "dense = keras.models.Sequential()\n",
    "dense.add(base_model)\n",
    "dense.add(keras.layers.GlobalAveragePooling2D())\n",
    "dense.add(keras.layers.Dropout(0.5))\n",
    "dense.add(keras.layers.Dense(5, activation='sigmoid'))\n",
    "\n",
    "dense.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.00005), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callback functions, to prevent overfitting, and model checkpointing\n",
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto')\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=2, factor=0.1, min_lr=1e-6, mode='auto', verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('models/dense_model_{epoch:02d}-{val_accuracy:.2f}ML.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_weights_only = True)\n",
    "lst_callbacks = [early_stopper, learning_rate_reduction, model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "86/85 [==============================] - ETA: -4s - loss: 0.4251 - accuracy: 0.4836\n",
      "Epoch 00001: val_accuracy improved from inf to 0.70197, saving model to dense_model_01-0.70.h5\n",
      "86/85 [==============================] - 2426s 28s/step - loss: 0.4251 - accuracy: 0.4836 - val_loss: 0.4322 - val_accuracy: 0.7020\n",
      "Epoch 2/15\n",
      "86/85 [==============================] - ETA: -4s - loss: 0.2208 - accuracy: 0.6256\n",
      "Epoch 00002: val_accuracy improved from 0.70197 to 0.60699, saving model to dense_model_02-0.61.h5\n",
      "86/85 [==============================] - 2110s 25s/step - loss: 0.2208 - accuracy: 0.6256 - val_loss: 0.2511 - val_accuracy: 0.6070\n",
      "Epoch 3/15\n",
      "86/85 [==============================] - ETA: -3s - loss: 0.1709 - accuracy: 0.6271  ETA: 6\n",
      "Epoch 00003: val_accuracy improved from 0.60699 to 0.57314, saving model to dense_model_03-0.57.h5\n",
      "86/85 [==============================] - 1881s 22s/step - loss: 0.1709 - accuracy: 0.6271 - val_loss: 0.1890 - val_accuracy: 0.5731\n",
      "Epoch 4/15\n",
      "86/85 [==============================] - ETA: -3s - loss: 0.1518 - accuracy: 0.6307\n",
      "Epoch 00004: val_accuracy did not improve from 0.57314\n",
      "86/85 [==============================] - 1883s 22s/step - loss: 0.1518 - accuracy: 0.6307 - val_loss: 0.1784 - val_accuracy: 0.6146\n",
      "Epoch 5/15\n",
      "86/85 [==============================] - ETA: -4s - loss: 0.1418 - accuracy: 0.6497\n",
      "Epoch 00005: val_accuracy did not improve from 0.57314\n",
      "86/85 [==============================] - 2241s 26s/step - loss: 0.1418 - accuracy: 0.6497 - val_loss: 0.1699 - val_accuracy: 0.6583\n",
      "Epoch 6/15\n",
      "86/85 [==============================] - ETA: -4s - loss: 0.1329 - accuracy: 0.6387\n",
      "Epoch 00006: val_accuracy did not improve from 0.57314\n",
      "86/85 [==============================] - 2155s 25s/step - loss: 0.1329 - accuracy: 0.6387 - val_loss: 0.1537 - val_accuracy: 0.6474\n",
      "Epoch 7/15\n",
      "86/85 [==============================] - ETA: -3s - loss: 0.1210 - accuracy: 0.6438\n",
      "Epoch 00007: val_accuracy did not improve from 0.57314\n",
      "86/85 [==============================] - 1678s 20s/step - loss: 0.1210 - accuracy: 0.6438 - val_loss: 0.1429 - val_accuracy: 0.6747\n",
      "Epoch 8/15\n",
      "86/85 [==============================] - ETA: -3s - loss: 0.1117 - accuracy: 0.6642\n",
      "Epoch 00008: val_accuracy did not improve from 0.57314\n",
      "86/85 [==============================] - 1624s 19s/step - loss: 0.1117 - accuracy: 0.6642 - val_loss: 0.1639 - val_accuracy: 0.6474\n",
      "Epoch 9/15\n",
      "86/85 [==============================] - ETA: -4s - loss: 0.1084 - accuracy: 0.6657\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.57314\n",
      "86/85 [==============================] - 2032s 24s/step - loss: 0.1084 - accuracy: 0.6657 - val_loss: 0.2362 - val_accuracy: 0.7293\n",
      "Epoch 10/15\n",
      "86/85 [==============================] - ETA: -4s - loss: 0.1025 - accuracy: 0.6642\n",
      "Epoch 00010: val_accuracy did not improve from 0.57314\n",
      "86/85 [==============================] - 2190s 25s/step - loss: 0.1025 - accuracy: 0.6642 - val_loss: 0.1353 - val_accuracy: 0.6867\n",
      "Epoch 11/15\n",
      "86/85 [==============================] - ETA: -4s - loss: 0.0955 - accuracy: 0.6617\n",
      "Epoch 00011: val_accuracy did not improve from 0.57314\n",
      "86/85 [==============================] - 2167s 25s/step - loss: 0.0955 - accuracy: 0.6617 - val_loss: 0.1318 - val_accuracy: 0.6736\n",
      "Epoch 12/15\n",
      "86/85 [==============================] - ETA: -3s - loss: 0.0977 - accuracy: 0.6650\n",
      "Epoch 00012: val_accuracy did not improve from 0.57314\n",
      "86/85 [==============================] - 1752s 20s/step - loss: 0.0977 - accuracy: 0.6650 - val_loss: 0.1346 - val_accuracy: 0.6845\n",
      "Epoch 13/15\n",
      "86/85 [==============================] - ETA: -3s - loss: 0.0998 - accuracy: 0.6602\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.57314\n",
      "86/85 [==============================] - 1886s 22s/step - loss: 0.0998 - accuracy: 0.6602 - val_loss: 0.1343 - val_accuracy: 0.6954\n",
      "Epoch 14/15\n",
      "86/85 [==============================] - ETA: -3s - loss: 0.0948 - accuracy: 0.6653\n",
      "Epoch 00014: val_accuracy did not improve from 0.57314\n",
      "86/85 [==============================] - 1870s 22s/step - loss: 0.0948 - accuracy: 0.6653 - val_loss: 0.1311 - val_accuracy: 0.6878\n",
      "Epoch 15/15\n",
      "86/85 [==============================] - ETA: -4s - loss: 0.0956 - accuracy: 0.6693\n",
      "Epoch 00015: val_accuracy did not improve from 0.57314\n",
      "86/85 [==============================] - 2078s 24s/step - loss: 0.0956 - accuracy: 0.6693 - val_loss: 0.1304 - val_accuracy: 0.6856\n"
     ]
    }
   ],
   "source": [
    "history = dense.fit_generator(\n",
    "    data_generator,\n",
    "    steps_per_epoch=x_train.shape[0] / BATCH_SIZE,\n",
    "    epochs=15,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=lst_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense.save(\"models/densenet121ML.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = dense.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the y value is considered if its greater than a specific threshold, in this case 0.5\n",
    "val_y = y_val_pred > 0.5\n",
    "#since we created multi labels, we can sum up the individual 1s to obtain the predicted class\n",
    "val_y = val_y.astype(int).sum(axis=1) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Val_y has the predicted classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluation Section</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we split this into variables, such that d will obtain the real y values in the validation set\n",
    "#a, b => Train\n",
    "#c, d => Validation (c -> id_code, d -> diagnosis)\n",
    "a, b, c, d = train_test_split(train_df['id_code'], train_df['diagnosis'], test_size=TEST_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_y = list(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[443   6   1   0   0]\n",
      " [ 13  51  17   0   0]\n",
      " [  6  40 170  34   7]\n",
      " [  0   1  13  15  15]\n",
      " [  0   3  26  19  36]]\n",
      "Accuracy Score : 0.7805676855895196\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       450\n",
      "           1       0.50      0.63      0.56        81\n",
      "           2       0.75      0.66      0.70       257\n",
      "           3       0.22      0.34      0.27        44\n",
      "           4       0.62      0.43      0.51        84\n",
      "\n",
      "    accuracy                           0.78       916\n",
      "   macro avg       0.61      0.61      0.60       916\n",
      "weighted avg       0.79      0.78      0.78       916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual = real_y\n",
    "predicted = val_y\n",
    "results = confusion_matrix(actual, predicted) \n",
    "  \n",
    "print ('Confusion Matrix :')\n",
    "print(results)\n",
    "print ('Accuracy Score :',accuracy_score(actual, predicted))\n",
    "print ('Report : ')\n",
    "print (classification_report(actual, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
