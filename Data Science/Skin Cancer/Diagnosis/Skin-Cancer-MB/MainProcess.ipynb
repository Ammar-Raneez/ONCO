{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inception Model\n",
    "from utils import *\n",
    "from InceptionModel import *\n",
    "\n",
    "ft_inception = fine_tuned_inception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "36/36 [==============================] - 176s 5s/step - loss: 0.6323 - accuracy: 0.7532 - val_loss: 0.3993 - val_accuracy: 0.8131\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 149s 4s/step - loss: 0.4796 - accuracy: 0.7952 - val_loss: 0.3880 - val_accuracy: 0.8283\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 150s 4s/step - loss: 0.3946 - accuracy: 0.8304 - val_loss: 0.3688 - val_accuracy: 0.8359\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 149s 4s/step - loss: 0.3463 - accuracy: 0.8519 - val_loss: 0.3687 - val_accuracy: 0.8283\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 150s 4s/step - loss: 0.3184 - accuracy: 0.8559 - val_loss: 0.3638 - val_accuracy: 0.8283\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 150s 4s/step - loss: 0.2925 - accuracy: 0.8693 - val_loss: 0.3544 - val_accuracy: 0.8434\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 140s 4s/step - loss: 0.2751 - accuracy: 0.8867 - val_loss: 0.3655 - val_accuracy: 0.8359\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 120s 3s/step - loss: 0.2453 - accuracy: 0.8960 - val_loss: 0.3592 - val_accuracy: 0.8333\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 118s 3s/step - loss: 0.2304 - accuracy: 0.9045 - val_loss: 0.3691 - val_accuracy: 0.8283\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 119s 3s/step - loss: 0.1874 - accuracy: 0.9277 - val_loss: 0.3615 - val_accuracy: 0.8460\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 118s 3s/step - loss: 0.1883 - accuracy: 0.9255 - val_loss: 0.3688 - val_accuracy: 0.8460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fe223ca688>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    verbose=0,\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "ft_inception.compile(\n",
    "    optimizer= Adam(learning_rate=1e-5),\n",
    "    loss ='binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "ft_inception.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[earlystopper],\n",
    "    validation_split=0.15,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_inception.save(\"models/InceptionModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ft_inception.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660,)\n",
      "[1 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1\n",
      " 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1\n",
      " 1 0 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0\n",
      " 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1\n",
      " 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 1 0 1 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0\n",
      " 0 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1\n",
      " 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0\n",
      " 1 0 0 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0\n",
      " 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1\n",
      " 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(y_pred, axis=1).shape)\n",
    "print(np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660,)\n",
      "[1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[306  54]\n",
      " [ 54 246]], shape=(2, 2), dtype=int32)\n",
      "Testing Accuracy: tf.Tensor(0.8363636363636363, shape=(), dtype=float64)\n",
      "Sensitivity: tf.Tensor(0.85, shape=(), dtype=float64)\n",
      "Specificity: tf.Tensor(0.82, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#generate confusion matrix\n",
    "import tensorflow as tf\n",
    "predictions = np.argmax(y_pred, axis=1)\n",
    "confusion_matrix = tf.math.confusion_matrix(labels=y_test, predictions=predictions)\n",
    "\n",
    "model_TP = confusion_matrix[0][0]\n",
    "model_TN = confusion_matrix[1][1]\n",
    "model_FN = confusion_matrix[1][0]\n",
    "model_FP = confusion_matrix[0][1]\n",
    "\n",
    "print(confusion_matrix)\n",
    "print(\"Testing Accuracy:\", (model_TP + model_TN) / (model_TP + model_TN + model_FP + model_FN))\n",
    "print(\"Sensitivity:\", (model_TP) / (model_TP + model_FN))\n",
    "print(\"Specificity:\", (model_TN) / (model_TN + model_FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16 Model\n",
    "from utils import *\n",
    "from VGG16Model import *\n",
    "\n",
    "ft_vgg = fine_tuned_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "36/36 [==============================] - 724s 20s/step - loss: 0.7862 - accuracy: 0.6176 - val_loss: 0.4445 - val_accuracy: 0.8258\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 701s 19s/step - loss: 0.5169 - accuracy: 0.7644 - val_loss: 0.4030 - val_accuracy: 0.8384\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 677s 19s/step - loss: 0.4455 - accuracy: 0.7988 - val_loss: 0.3877 - val_accuracy: 0.8333\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 678s 19s/step - loss: 0.3980 - accuracy: 0.8121 - val_loss: 0.3718 - val_accuracy: 0.8409\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 618s 17s/step - loss: 0.3566 - accuracy: 0.8385 - val_loss: 0.3626 - val_accuracy: 0.8409\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 569s 16s/step - loss: 0.3265 - accuracy: 0.8541 - val_loss: 0.3466 - val_accuracy: 0.8409\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 581s 16s/step - loss: 0.3132 - accuracy: 0.8572 - val_loss: 0.3463 - val_accuracy: 0.8535\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 598s 17s/step - loss: 0.3276 - accuracy: 0.8550 - val_loss: 0.3494 - val_accuracy: 0.8384\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 585s 16s/step - loss: 0.2862 - accuracy: 0.8706 - val_loss: 0.3272 - val_accuracy: 0.8485\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 600s 17s/step - loss: 0.2739 - accuracy: 0.8777 - val_loss: 0.3277 - val_accuracy: 0.8636\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 590s 16s/step - loss: 0.2600 - accuracy: 0.8804 - val_loss: 0.3546 - val_accuracy: 0.8283\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 591s 16s/step - loss: 0.2852 - accuracy: 0.8706 - val_loss: 0.3376 - val_accuracy: 0.8510\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 596s 17s/step - loss: 0.2505 - accuracy: 0.8884 - val_loss: 0.3202 - val_accuracy: 0.8636\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 702s 19s/step - loss: 0.2283 - accuracy: 0.9041 - val_loss: 0.3318 - val_accuracy: 0.8535\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 670s 19s/step - loss: 0.2121 - accuracy: 0.9116 - val_loss: 0.3234 - val_accuracy: 0.8586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fd0cf27c88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    verbose=0,\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "ft_vgg.compile(\n",
    "    optimizer= Adam(learning_rate=1e-5),\n",
    "    loss ='binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "ft_vgg.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=[earlystopper],\n",
    "    validation_split=0.15,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_vgg.save(\"models/VGGModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_vgg = ft_vgg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[311  49]\n",
      " [ 46 254]], shape=(2, 2), dtype=int32)\n",
      "Testing Accuracy: tf.Tensor(0.8560606060606061, shape=(), dtype=float64)\n",
      "Sensitivity: tf.Tensor(0.8711484593837535, shape=(), dtype=float64)\n",
      "Specificity: tf.Tensor(0.8382838283828383, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#generate confusion matrix\n",
    "import tensorflow as tf\n",
    "predictions_vgg = np.argmax(y_pred_vgg, axis=1)\n",
    "confusion_matrix = tf.math.confusion_matrix(labels=y_test, predictions=predictions_vgg)\n",
    "\n",
    "model_TP = confusion_matrix[0][0]\n",
    "model_TN = confusion_matrix[1][1]\n",
    "model_FN = confusion_matrix[1][0]\n",
    "model_FP = confusion_matrix[0][1]\n",
    "\n",
    "print(confusion_matrix)\n",
    "print(\"Testing Accuracy:\", (model_TP + model_TN) / (model_TP + model_TN + model_FP + model_FN))\n",
    "print(\"Sensitivity:\", (model_TP) / (model_TP + model_FN))\n",
    "print(\"Specificity:\", (model_TN) / (model_TN + model_FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94674944/94668760 [==============================] - 65s 1us/step\n"
     ]
    }
   ],
   "source": [
    "#resnet50 Model\n",
    "from utils import *\n",
    "from Resnet50Model import *\n",
    "\n",
    "ft_resnet = fine_tuned_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "36/36 [==============================] - 423s 12s/step - loss: 1.3988 - accuracy: 0.6693 - val_loss: 0.7886 - val_accuracy: 0.7525\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 250s 7s/step - loss: 0.8344 - accuracy: 0.7863 - val_loss: 0.4443 - val_accuracy: 0.8510\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 247s 7s/step - loss: 0.5769 - accuracy: 0.8336 - val_loss: 0.4339 - val_accuracy: 0.8561\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 245s 7s/step - loss: 0.3981 - accuracy: 0.8657 - val_loss: 0.4394 - val_accuracy: 0.8737\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 239s 7s/step - loss: 0.3098 - accuracy: 0.8880 - val_loss: 0.4299 - val_accuracy: 0.8586\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 238s 7s/step - loss: 0.2202 - accuracy: 0.9081 - val_loss: 0.4525 - val_accuracy: 0.8561\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 241s 7s/step - loss: 0.1970 - accuracy: 0.9210 - val_loss: 0.5052 - val_accuracy: 0.8485\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 239s 7s/step - loss: 0.1443 - accuracy: 0.9447 - val_loss: 0.4402 - val_accuracy: 0.8662\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 226s 6s/step - loss: 0.1196 - accuracy: 0.9545 - val_loss: 0.4496 - val_accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f38dc5e688>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    verbose=0,\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "ft_resnet.compile(\n",
    "    optimizer= Adam(learning_rate=1e-5),\n",
    "    loss ='binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "ft_resnet.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[earlystopper],\n",
    "    validation_split=0.15,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_resnet.save(\"models/ResnetModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_resnet = ft_resnet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[316  44]\n",
      " [ 52 248]], shape=(2, 2), dtype=int32)\n",
      "Testing Accuracy: tf.Tensor(0.8545454545454545, shape=(), dtype=float64)\n",
      "Sensitivity: tf.Tensor(0.8586956521739131, shape=(), dtype=float64)\n",
      "Specificity: tf.Tensor(0.8493150684931506, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#generate confusion matrix\n",
    "import tensorflow as tf\n",
    "predictions_resnet = np.argmax(y_pred_resnet, axis=1)\n",
    "confusion_matrix = tf.math.confusion_matrix(labels=y_test, predictions=predictions_resnet)\n",
    "\n",
    "model_TP = confusion_matrix[0][0]\n",
    "model_TN = confusion_matrix[1][1]\n",
    "model_FN = confusion_matrix[1][0]\n",
    "model_FP = confusion_matrix[0][1]\n",
    "\n",
    "print(confusion_matrix)\n",
    "print(\"Testing Accuracy:\", (model_TP + model_TN) / (model_TP + model_TN + model_FP + model_FN))\n",
    "print(\"Sensitivity:\", (model_TP) / (model_TP + model_FN))\n",
    "print(\"Specificity:\", (model_TN) / (model_TN + model_FP))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
